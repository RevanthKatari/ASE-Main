# Evidence Log

Track how research informs each MVP decision. Update this table after every interview, survey iteration, or usability test.

| Date | Activity | Key Insight | Impact on Requirements | Outstanding Questions |
| --- | --- | --- | --- | --- |
| 2025-09-25 | Google Form (22 responses, biased questions) | Housing and event info felt fragmented, but survey forced agreement; sample skewed toward classmates. | Triggered initial idea of central hub, but evidence is weak. Treat as hypothesis only. | Need neutral wording, more diverse participants, and space for “no issue” answers. |
| 2025-11-05 | Instructor feedback review | Highlighted lack of reasoning and misuse of buzzwords. | Scope narrowed to listings + events; added rule that every feature must cite evidence. | How to validate features with real users instead of assumptions? |
| 2025-11-10 (planned) | Semi-structured interview – newcomer | *Fill after session* | *Fill after session* | What info would build trust in listings? |
| 2025-11-11 (planned) | Semi-structured interview – local volunteer | *Fill after session* | *Fill after session* | What moderation workload is sustainable? |

**Instructions**
1. Record raw notes in a shared document immediately after each session.
2. Summarize the insight here using concise, verifiable language.
3. For every new requirement or feature idea, cite the row ID (date) that supports it.
4. If evidence contradicts an existing assumption, document the change and adjust the backlog.

